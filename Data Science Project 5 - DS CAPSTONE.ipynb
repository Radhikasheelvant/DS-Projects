{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb11fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import emoji\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719bd3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startsWithDateAndTime(s):\n",
    "    pattern = r\"[\\d]{1,2}/[\\d]{1,2}/[\\d]{4}\" #, r\"([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -\" # [\\d]{1,2}/[\\d]{1,2}/[\\d]{4} ^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+)\n",
    "    result = re.findall(pattern, s)\n",
    "    print(\"result :\", result)\n",
    "    if result:\n",
    "        return True\n",
    "    else:\n",
    "        False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec0c2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindAuthor(s):\n",
    "    s=s.split(\":\")\n",
    "    if len(s)==2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7460b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataPoint(line):\n",
    "    splitLine = line.split(' - ')\n",
    "    dateTime = splitLine[0]\n",
    "    date, time = dateTime.split(', ')\n",
    "    message = ' '.join(splitLine[1:])\n",
    "    if FindAuthor(message):\n",
    "        splitMessage = message.split(': ')\n",
    "        author = splitMessage[0]\n",
    "        message = ' '.join(splitMessage[1:])\n",
    "    else:\n",
    "        author = None\n",
    "    return date, time, author, message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77e7b878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp.readline() : \n",
      " 26/08/2023, 16:56 - Radhika: Hii aik na\n",
      "\n",
      "messageBuffer : \n",
      " []\n",
      "line: \n",
      " 26/08/2023, 16:57 - Radhika: Te aarti chya bride to be chya veli tu te aanal hot na team bride vagere te tsl kuth bhetat\n",
      "result : ['26/08/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 26/08/2023, 16:57 - Radhika: Ani ky mhntat tyala\n",
      "result : ['26/08/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 26/08/2023, 19:22 - Chaitu: Props boltat\n",
      "result : ['26/08/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 26/08/2023, 19:22 - Chaitu: Nd te ghari bnvl hott\n",
      "result : ['26/08/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 26/08/2023, 19:22 - Chaitu: Tula online or nupur ch shejari ek shop ahe tith bhetl hadapsar mdhe\n",
      "result : ['26/08/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 26/08/2023, 19:23 - Chaitu: I think so\n",
      "result : ['26/08/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 26/08/2023, 19:27 - Radhika: Okay\n",
      "result : ['26/08/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 26/08/2023, 19:27 - Radhika: Thike check krte\n",
      "result : ['26/08/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 26/08/2023, 19:27 - Radhika: Thanks\n",
      "result : ['26/08/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 10/09/2023, 00:13 - Chaitu: Zop radhe ...\n",
      "result : ['10/09/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 10/09/2023, 00:14 - Chaitu: Negative status tkti ly\n",
      "result : ['10/09/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 10/09/2023, 08:05 - Radhika: üòÅüòÅ\n",
      "result : ['10/09/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 10/09/2023, 08:05 - Radhika: Tuz laksh rhil phije na mazyavr thod\n",
      "result : ['10/09/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 10/09/2023, 08:05 - Radhika: Btw good morning üåÑ\n",
      "result : ['10/09/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 10/09/2023, 10:15 - Chaitu: Gm\n",
      "result : ['10/09/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 01/10/2023, 20:23 - Radhika: Aaj ka post takliyes?\n",
      "result : ['01/10/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 01/10/2023, 21:01 - Chaitu: Ka g\n",
      "result : ['01/10/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 01/10/2023, 22:21 - Radhika: June pic aahet Naa mhnun mhntal\n",
      "result : ['01/10/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 01/10/2023, 22:24 - Chaitu: New ahe radhe\n",
      "result : ['01/10/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 01/10/2023, 22:24 - Chaitu: Me June pics tkl ka\n",
      "result : ['01/10/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 01/10/2023, 22:27 - Radhika: Kdi che??\n",
      "result : ['01/10/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 01/10/2023, 22:40 - Chaitu: Sep mdhe zal ata bhava ch engagement\n",
      "result : ['01/10/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 01/10/2023, 22:50 - Radhika: Ok ok\n",
      "result : ['01/10/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 31/10/2023, 17:31 - Chaitu: null\n",
      "result : ['31/10/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 03/11/2023, 11:43 - Radhika: Chaite\n",
      "result : ['03/11/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " Me te wfh krtiye te karaych ka tula\n",
      "result : []\n",
      "line: \n",
      " 03/11/2023, 11:43 - Radhika: Reel banvayche roj\n",
      "result : ['03/11/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 03/11/2023, 11:43 - Radhika: Pn paise bharave lagtil adi\n",
      "result : ['03/11/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 03/11/2023, 11:50 - Chaitu: Ksl ahe te\n",
      "result : ['03/11/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 03/11/2023, 11:56 - Radhika: https://instagram.com/creatorradhika?igshid=OGQ5ZDc2ODk2ZA==\n",
      "result : ['03/11/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 08/12/2023, 17:04 - Chaitu: üòç\n",
      "result : ['08/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 08/12/2023, 18:34 - Radhika: ‚ù§Ô∏èü´∞üèª\n",
      "result : ['08/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 09:15 - Radhika: Heyy\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 09:17 - Chaitu: Bol ki\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 09:17 - Chaitu: Gud morning\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 09:18 - Radhika: Good morning üåû\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 09:18 - Radhika: Ky krtey\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 09:18 - Radhika: Lai divas zal bolan ny zal mhnun kela mag\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 09:18 - Radhika: Ky challay\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 09:18 - Chaitu: Call krych na mg\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 09:18 - Chaitu: Ata mandira mdhe aley\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 09:18 - Radhika: Evdya sakali\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 09:19 - Radhika: Ok ok\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " Krte call mng thodya time ne\n",
      "result : []\n",
      "line: \n",
      " 12/12/2023, 09:19 - Chaitu: Ho\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 09:19 - Chaitu: Amch ithe saptah ahe\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 09:19 - Chaitu: Dupari kr\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 09:19 - Radhika: Hoo chalel\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 22:24 - Radhika: Are me baner la veleli interview la\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 22:24 - Radhika: 5la ale\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " Lai thkle\n",
      "result : []\n",
      "line: \n",
      " Mng Yeun zople\n",
      "result : []\n",
      "line: \n",
      " 12/12/2023, 22:24 - Radhika: Udya krte call nakki\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n",
      "line: \n",
      " 12/12/2023, 22:32 - Chaitu: Kk\n",
      "result : ['12/12/2023']\n",
      "startsWithDateAndTime : \n",
      " <function startsWithDateAndTime at 0x0000025FFCA38E50>\n"
     ]
    }
   ],
   "source": [
    "parsedData = []\n",
    "conversation = \"C:\\\\Users\\\\Radhika\\\\Downloads\\\\WhatsApp Chat with Chaitu.txt\" # path for the whatsapp text file\n",
    "with open(conversation, encoding=\"utf-8\") as fp:\n",
    "\n",
    "    fp.readline() # Skipping first line of the file because contains information related to something about end-to-end encryption\n",
    "    print(\"fp.readline() : \\n\", fp.readline())\n",
    "    messageBuffer = []\n",
    "    print(\"messageBuffer : \\n\", messageBuffer)\n",
    "    date, time, author = None, None, None\n",
    "    while True:\n",
    "        line = fp.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        print(\"line: \\n\", line)\n",
    "        if startsWithDateAndTime(line):\n",
    "            print(\"startsWithDateAndTime : \\n\", startsWithDateAndTime)\n",
    "            if len(messageBuffer) > 0:\n",
    "                parsedData.append([date, time, author, ' '.join(messageBuffer)])\n",
    "                messageBuffer.clear()\n",
    "                date, time, author, message = getDataPoint(line)\n",
    "                messageBuffer.append(message)\n",
    "\n",
    "        else:\n",
    "            messageBuffer.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c127bf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Author</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-08-12</td>\n",
       "      <td>17:04</td>\n",
       "      <td>Chaitu</td>\n",
       "      <td>üòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-08-12</td>\n",
       "      <td>18:34</td>\n",
       "      <td>Radhika</td>\n",
       "      <td>‚ù§Ô∏èü´∞üèª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:15</td>\n",
       "      <td>Radhika</td>\n",
       "      <td>Heyy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:17</td>\n",
       "      <td>Chaitu</td>\n",
       "      <td>Bol ki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:17</td>\n",
       "      <td>Chaitu</td>\n",
       "      <td>Gud morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:18</td>\n",
       "      <td>Radhika</td>\n",
       "      <td>Good morning üåû</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:18</td>\n",
       "      <td>Radhika</td>\n",
       "      <td>Ky krtey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:18</td>\n",
       "      <td>Radhika</td>\n",
       "      <td>Lai divas zal bolan ny zal mhnun kela mag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:18</td>\n",
       "      <td>Radhika</td>\n",
       "      <td>Ky challay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:18</td>\n",
       "      <td>Chaitu</td>\n",
       "      <td>Call krych na mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:18</td>\n",
       "      <td>Chaitu</td>\n",
       "      <td>Ata mandira mdhe aley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:18</td>\n",
       "      <td>Radhika</td>\n",
       "      <td>Evdya sakali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:19</td>\n",
       "      <td>Radhika</td>\n",
       "      <td>Ok ok Krte call mng thodya time ne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:19</td>\n",
       "      <td>Chaitu</td>\n",
       "      <td>Ho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:19</td>\n",
       "      <td>Chaitu</td>\n",
       "      <td>Amch ithe saptah ahe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:19</td>\n",
       "      <td>Chaitu</td>\n",
       "      <td>Dupari kr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>09:19</td>\n",
       "      <td>Radhika</td>\n",
       "      <td>Hoo chalel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>22:24</td>\n",
       "      <td>Radhika</td>\n",
       "      <td>Are me baner la veleli interview la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>22:24</td>\n",
       "      <td>Radhika</td>\n",
       "      <td>5la ale Lai thkle Mng Yeun zople</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>22:24</td>\n",
       "      <td>Radhika</td>\n",
       "      <td>Udya krte call nakki</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Time   Author                                    Message\n",
       "5  2023-08-12  17:04   Chaitu                                          üòç\n",
       "6  2023-08-12  18:34  Radhika                                       ‚ù§Ô∏èü´∞üèª\n",
       "7  2023-12-12  09:15  Radhika                                       Heyy\n",
       "8  2023-12-12  09:17   Chaitu                                     Bol ki\n",
       "9  2023-12-12  09:17   Chaitu                                Gud morning\n",
       "10 2023-12-12  09:18  Radhika                             Good morning üåû\n",
       "11 2023-12-12  09:18  Radhika                                   Ky krtey\n",
       "12 2023-12-12  09:18  Radhika  Lai divas zal bolan ny zal mhnun kela mag\n",
       "13 2023-12-12  09:18  Radhika                                 Ky challay\n",
       "14 2023-12-12  09:18   Chaitu                           Call krych na mg\n",
       "15 2023-12-12  09:18   Chaitu                      Ata mandira mdhe aley\n",
       "16 2023-12-12  09:18  Radhika                               Evdya sakali\n",
       "17 2023-12-12  09:19  Radhika         Ok ok Krte call mng thodya time ne\n",
       "18 2023-12-12  09:19   Chaitu                                         Ho\n",
       "19 2023-12-12  09:19   Chaitu                       Amch ithe saptah ahe\n",
       "20 2023-12-12  09:19   Chaitu                                  Dupari kr\n",
       "21 2023-12-12  09:19  Radhika                                 Hoo chalel\n",
       "22 2023-12-12  22:24  Radhika        Are me baner la veleli interview la\n",
       "23 2023-12-12  22:24  Radhika           5la ale Lai thkle Mng Yeun zople\n",
       "24 2023-12-12  22:24  Radhika                       Udya krte call nakki"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(parsedData, columns=['Date', 'Time', 'Author', 'Message']) # Initialising a pandas Dataframe.\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13b31ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, 'Radhika', 'Chaitu'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Author.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f27e1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media: 0\n",
      "Emojis: 4\n",
      "Links: 1\n"
     ]
    }
   ],
   "source": [
    "media_messages = df[df['Message'] == '<Media omitted>'].shape[0]\n",
    "# print(media_messages)\n",
    "\n",
    "def split_count(text):\n",
    "    data = re.findall(r'\\X', text)\n",
    "    emoji_list = []\n",
    "\n",
    "    for word in data:\n",
    "        emojis = emoji.distinct_emoji_list(word)\n",
    "        emoji_list.extend([emoji.demojize(is_emoji) for is_emoji in emojis])\n",
    "\n",
    "    # emoji_list = []\n",
    "    # for word in data:\n",
    "    #   if any(char in emoji.distinct_emoji_list for char in word):\n",
    "    #     emoji_list.append(word)\n",
    "\n",
    "    return emoji_list\n",
    "\n",
    "df[\"emoji\"] = df[\"Message\"].apply(split_count)\n",
    "emojis = sum(df['emoji'].str.len())\n",
    "# print(emojis)\n",
    "URLPATTERN = r'(https?://\\S+)'\n",
    "df['urlcount'] = df.Message.apply(lambda x: re.findall(URLPATTERN, x)).str.len()\n",
    "links = np.sum(df.urlcount)\n",
    "# print(\"Data science Community\")\n",
    "# print(\"Messages:\",total_messages)\n",
    "print(\"Media:\",media_messages)\n",
    "print(\"Emojis:\",emojis)\n",
    "print(\"Links:\",links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81a14952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Date      24 non-null     datetime64[ns]\n",
      " 1   Time      24 non-null     object        \n",
      " 2   Author    23 non-null     object        \n",
      " 3   Message   25 non-null     object        \n",
      " 4   emoji     25 non-null     object        \n",
      " 5   urlcount  25 non-null     int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 1.3+ KB\n",
      "\n",
      "\n",
      "Stats of Radhika -\n",
      "Messages Sent 14\n",
      "Words per message 4.0\n",
      "Media Messages Sent 0\n",
      "Emojis Sent 3\n",
      "Links Sent 0\n",
      "\n",
      "\n",
      "Stats of Chaitu -\n",
      "Messages Sent 9\n",
      "Words per message 2.5555555555555554\n",
      "Media Messages Sent 0\n",
      "Emojis Sent 1\n",
      "Links Sent 0\n"
     ]
    }
   ],
   "source": [
    "media_messages_df = df[df['Message'] == '<Media omitted>']\n",
    "messages_df = df.drop(media_messages_df.index)\n",
    "messages_df.info()\n",
    "messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))\n",
    "messages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))\n",
    "messages_df[\"MessageCount\"]=1\n",
    "\n",
    "l = ['Radhika','Chaitu'] # list of the authors name in the group\n",
    "\n",
    "for i in range(len(l)):\n",
    "    # Filtering out messages of particular user\n",
    "    req_df= messages_df[messages_df[\"Author\"] == l[i]]\n",
    "    # req_df will contain messages of only one particular user\n",
    "    print('\\n')\n",
    "    print(f'Stats of {l[i]} -')\n",
    "    # shape will print number of rows which indirectly means the number of messages\n",
    "    print('Messages Sent', req_df.shape[0])\n",
    "    #Word_Count contains of total words in one message. Sum of all words/ Total Messages will yield words per message\n",
    "    words_per_message = (np.sum(req_df['Word_Count']))/req_df.shape[0]\n",
    "    print('Words per message', words_per_message)\n",
    "    #media conists of media messages\n",
    "    media = media_messages_df[media_messages_df['Author'] == l[i]].shape[0]\n",
    "    print('Media Messages Sent', media)\n",
    "    # emojis conists of total emojis\n",
    "    emojis = sum(req_df['emoji'].str.len())\n",
    "    print('Emojis Sent', emojis)\n",
    "    #links consist of total links\n",
    "    links = sum(req_df[\"urlcount\"])\n",
    "    print('Links Sent', links)\n",
    "    # print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "319522c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(':smiling_face_with_heart-eyes:', 1)\n",
      "(':red_heart:', 1)\n",
      "(':hand_with_index_finger_and_thumb_crossed_light_skin_tone:', 1)\n",
      "(':sun_with_face:', 1)\n"
     ]
    }
   ],
   "source": [
    "total_emojis_list = list([a for b in messages_df.emoji for a in b])\n",
    "emoji_dict = dict(Counter(total_emojis_list))\n",
    "emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "for i in emoji_dict:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32ab684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 493 words in all the messages.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m stopwords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(STOPWORDS)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Generate a word cloud image with specific font_path\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\", font_path='‚Ä™‚Ä™C:\\Windows\\Fonts\\GARABD.TTF').generate(text)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Display the generated image using Matplotlib\u001b[39;00m\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:642\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \n\u001b[0;32m    630\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:624\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \n\u001b[0;32m    609\u001b[0m \u001b[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    623\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_text(text)\n\u001b[1;32m--> 624\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:453\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    451\u001b[0m     font_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfrequencies\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmax_font_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;66;03m# find font sizes\u001b[39;00m\n\u001b[0;32m    456\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout_]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:511\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    508\u001b[0m transposed_font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mTransposedFont(\n\u001b[0;32m    509\u001b[0m     font, orientation\u001b[38;5;241m=\u001b[39morientation)\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# get size of resulting text\u001b[39;00m\n\u001b[1;32m--> 511\u001b[0m box_size \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtextbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransposed_font\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# find possible places using integral image:\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m occupancy\u001b[38;5;241m.\u001b[39msample_position(box_size[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[0;32m    514\u001b[0m                                    box_size[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[0;32m    515\u001b[0m                                    random_state)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\ImageDraw.py:671\u001b[0m, in \u001b[0;36mImageDraw.textbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    669\u001b[0m     font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetfont()\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(font, ImageFont\u001b[38;5;241m.\u001b[39mFreeTypeFont):\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly supported for TrueType fonts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    672\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedded_color \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfontmode\n\u001b[0;32m    673\u001b[0m bbox \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mgetbbox(\n\u001b[0;32m    674\u001b[0m     text, mode, direction, features, language, stroke_width, anchor\n\u001b[0;32m    675\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "text = \" \".join(review for review in messages_df.Message)\n",
    "print(\"There are {} words in all the messages.\".format(len(text)))\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "# Generate a word cloud image with specific font_path\n",
    "#wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\", font_path='‚Ä™‚Ä™C:\\Windows\\Fonts\\GARABD.TTF').generate(text)\n",
    "#wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"black\").generate(text)\n",
    "\n",
    "# Display the generated image using Matplotlib\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "#plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61cdab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['Radhika','Chaitu']\n",
    "for i in range(len(l)):\n",
    "    dummy_df = messages_df[messages_df['Author'] == l[i]]\n",
    "    text = \" \".join(review for review in dummy_df.Message)\n",
    "    stopwords = set(STOPWORDS)\n",
    "    #Generate a word cloud image\n",
    "    print('Author name',l[i])\n",
    "    wordcloud = WordCloud(stopwords=stopwords, interpolation='bilinear').generate(text)\n",
    "    #Display the generated image\n",
    "    plt.figure( figsize=(10,5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "631545db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Radhika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Radhika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m chat_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mRadhika\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mWhatsApp Chat with Chaitu.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Assuming your chat data has a 'text' column\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m text_data \u001b[38;5;241m=\u001b[39m \u001b[43mchat_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Preprocessing the text data\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_text\u001b[39m(text):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Convert to lowercase\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load chat data (replace 'your_chat_data.csv' with your actual file)\n",
    "chat_data = \"C:\\\\Users\\\\Radhika\\\\Downloads\\\\WhatsApp Chat with Chaitu.txt\" \n",
    "\n",
    "# Assuming your chat data has a 'text' column\n",
    "text_data = chat_data['text'].astype(str)\n",
    "\n",
    "# Preprocessing the text data\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and numbers\n",
    "    text = ''.join([char for char in text if char.isalpha() or char.isspace()])\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to each text in the dataset\n",
    "text_data_processed = text_data.apply(preprocess_text)\n",
    "\n",
    "# Combine processed text into a single string\n",
    "combined_text = ' '.join(text_data_processed)\n",
    "\n",
    "# Create WordCloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(combined_text)\n",
    "\n",
    "# Display WordCloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud of Chat Data\")\n",
    "plt.show()\n",
    "\n",
    "# Save WordCloud image\n",
    "wordcloud.to_file(\"wordcloud_chat_data.png\")\n",
    "\n",
    "# Sentiment Analysis using NLTK's SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Example: Analyzing sentiment of a single sentence\n",
    "example_sentence = \"I love this product! It's amazing.\"\n",
    "sentiment_scores = sia.polarity_scores(example_sentence)\n",
    "print(f\"Sentiment Scores: {sentiment_scores}\")\n",
    "\n",
    "# Analyzing sentiment of the entire chat data\n",
    "sentiments = text_data.apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "chat_data['sentiment'] = sentiments\n",
    "\n",
    "# Display the first few rows of the chat data with sentiment scores\n",
    "print(chat_data[['text', 'sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "321effaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "We need at least 1 word to plot a word cloud, got 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Create Word Cloud\u001b[39;00m\n\u001b[0;32m     37\u001b[0m text_for_wordcloud \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_message\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 38\u001b[0m wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_for_wordcloud\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(wordcloud)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Display the Word Cloud\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:642\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \n\u001b[0;32m    630\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:624\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \n\u001b[0;32m    609\u001b[0m \u001b[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    623\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_text(text)\n\u001b[1;32m--> 624\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:410\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    408\u001b[0m frequencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(frequencies\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39mitemgetter(\u001b[38;5;241m1\u001b[39m), reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(frequencies) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe need at least 1 word to plot a word cloud, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(frequencies))\n\u001b[0;32m    412\u001b[0m frequencies \u001b[38;5;241m=\u001b[39m frequencies[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_words]\n\u001b[0;32m    414\u001b[0m \u001b[38;5;66;03m# largest entry will be 1\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: We need at least 1 word to plot a word cloud, got 0."
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load the chat data from the text file\n",
    "conversation_path = \"C:\\\\Users\\\\Radhika\\\\Downloads\\\\WhatsApp Chat with Chaitu.txt\"\n",
    "with open(conversation_path, 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "# Extracting messages and timestamps using regular expressions\n",
    "pattern = re.compile(r'(\\d{1,2}/\\d{1,2}/\\d{2,4},? \\d{1,2}:\\d{2} [APMapm]{2} - .+?): (.+)')\n",
    "matches = pattern.findall(raw_text)\n",
    "data = {'timestamp': [], 'message': []}\n",
    "for match in matches:\n",
    "    timestamp, message = match\n",
    "    data['timestamp'].append(timestamp)\n",
    "    data['message'].append(message)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess the text data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "df['clean_message'] = df['message'].apply(preprocess_text)\n",
    "\n",
    "# Create Word Cloud\n",
    "text_for_wordcloud = ' '.join(df['clean_message'])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"black\").generate(text_for_wordcloud)\n",
    "print(wordcloud)\n",
    "# Display the Word Cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Save the Word Cloud image\n",
    "wordcloud.to_file(\"wordcloud.png\")\n",
    "\n",
    "# Perform Sentiment Analysis using TextBlob\n",
    "df['sentiment'] = df['clean_message'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# Display Sentiment Distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "df['sentiment'].plot(kind='hist', bins=20, edgecolor='black')\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.xlabel('Sentiment Polarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ebb35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba40d598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
